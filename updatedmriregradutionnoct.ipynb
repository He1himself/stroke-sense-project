{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# --- Import Libraries ---\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "h2W6s6dLJtAE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow / Keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dropout, Dense, GlobalAveragePooling2D, BatchNormalization, Input\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "zHuunofsJ_Y0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk('/content/stroke_dataset'):\n",
        "    print(f\"üìÅ Directory: {dirpath}\")\n",
        "    if dirnames:\n",
        "        print(f\"üìÇ Subdirs: {dirnames}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-jkHIVFLKVv",
        "outputId": "1d77e8ca-4853-4a23-8d36-1d98a479ae5a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Directory: /content/stroke_dataset\n",
            "üìÇ Subdirs: ['Stroke_classification']\n",
            "üìÅ Directory: /content/stroke_dataset/Stroke_classification\n",
            "üìÇ Subdirs: ['Ischemic', 'Haemorrhagic', 'Normal']\n",
            "üìÅ Directory: /content/stroke_dataset/Stroke_classification/Ischemic\n",
            "üìÅ Directory: /content/stroke_dataset/Stroke_classification/Haemorrhagic\n",
            "üìÅ Directory: /content/stroke_dataset/Stroke_classification/Normal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/stroke_dataset/Stroke_classification'\n"
      ],
      "metadata": {
        "id": "o3YQ4kPFLKZd"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Double-check the file path and file existence\n",
        "file_path = '/content/Stroke_classification.zip'\n",
        "if os.path.exists(file_path):\n",
        "    print(f\"File found at: {file_path}\")\n",
        "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/stroke_dataset')\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è File not found at: {file_path}. Please re-upload or re-download.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGenZ7DUPRRO",
        "outputId": "32ec9784-1f83-4a0b-f0ec-92888c262171"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found at: /content/Stroke_classification.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/Stroke_classification.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/stroke_dataset')\n"
      ],
      "metadata": {
        "id": "QB8SQSOQLKSJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "# TensorFlow / Keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dropout, Dense, GlobalAveragePooling2D, BatchNormalization, Input\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "# --- Data Loading Function ---\n",
        "def load_data(base_path, categories, img_size=(224, 224), augment_minority=True):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    datagen_aug = ImageDataGenerator(\n",
        "        rotation_range=30,\n",
        "        width_shift_range=0.3,\n",
        "        height_shift_range=0.3,\n",
        "        zoom_range=0.3,\n",
        "        brightness_range=[0.5, 1.5],\n",
        "        horizontal_flip=True,\n",
        "        shear_range=0.3,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    for label, category in enumerate(categories):\n",
        "        category_path = os.path.join(base_path, category)\n",
        "        if not os.path.exists(category_path):\n",
        "            print(f\"‚ö†Ô∏è Directory not found: {category_path}\")\n",
        "            continue\n",
        "\n",
        "        category_images = []\n",
        "        for img_file in os.listdir(category_path):\n",
        "            img_path = os.path.join(category_path, img_file)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                img = cv2.resize(img, img_size)\n",
        "                category_images.append(img)\n",
        "\n",
        "        category_images = np.array(category_images)\n",
        "\n",
        "        if augment_minority and len(category_images) < 300:\n",
        "            print(f\"üîÅ Augmenting class '{category}' with {len(category_images)} images\")\n",
        "            category_images = category_images.reshape((-1, img_size[0], img_size[1], 3))\n",
        "            extra = 300 - len(category_images)\n",
        "            aug_iter = datagen_aug.flow(category_images, batch_size=1)\n",
        "            for _ in range(extra):\n",
        "                aug_img = next(aug_iter)[0].astype(np.uint8)\n",
        "                images.append(aug_img)\n",
        "                labels.append(label)\n",
        "\n",
        "        for img in category_images:\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = to_categorical(labels, num_classes=len(categories))\n",
        "    return images, labels\n",
        "# --- Load Data ---\n",
        "categories = ['Normal', 'Ischemic', 'Haemorrhagic']\n",
        "data_path = '/content/stroke_dataset/Stroke_classification'\n",
        "images, labels = load_data(data_path, categories) #Calling the load_data function to initialize the 'images' and 'labels' variables\n",
        "\n",
        "# Optional: check class balance\n",
        "labels_numeric = np.argmax(labels, axis=1)\n",
        "print(\"Class distribution:\", Counter(labels_numeric))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuKIDVo7PpWe",
        "outputId": "4c2dd7d9-6883-4781-966d-6e143bb3157d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÅ Augmenting class 'Ischemic' with 30 images\n",
            "üîÅ Augmenting class 'Haemorrhagic' with 186 images\n",
            "Class distribution: Counter({np.int64(0): 399, np.int64(1): 300, np.int64(2): 300})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: check class balance\n",
        "labels_numeric = np.argmax(labels, axis=1)\n",
        "print(\"Class distribution:\", Counter(labels_numeric))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3KmtFpyOsuI",
        "outputId": "5e7490c4-8407-4b47-e4b5-442bd50e6b38"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution: Counter({np.int64(0): 399, np.int64(1): 300, np.int64(2): 300})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Data Loading Function ---\n",
        "def load_data(base_path, categories, img_size=(224, 224), augment_minority=True):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    datagen_aug = ImageDataGenerator(\n",
        "        rotation_range=30,\n",
        "        width_shift_range=0.3,\n",
        "        height_shift_range=0.3,\n",
        "        zoom_range=0.3,\n",
        "        brightness_range=[0.5, 1.5],\n",
        "        horizontal_flip=True,\n",
        "        shear_range=0.3,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    for label, category in enumerate(categories):\n",
        "        category_path = os.path.join(base_path, category)\n",
        "        if not os.path.exists(category_path):\n",
        "            print(f\"‚ö†Ô∏è Directory not found: {category_path}\")\n",
        "            continue\n",
        "\n",
        "        category_images = []\n",
        "        for img_file in os.listdir(category_path):\n",
        "            img_path = os.path.join(category_path, img_file)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                img = cv2.resize(img, img_size)\n",
        "                category_images.append(img)\n",
        "\n",
        "        category_images = np.array(category_images)\n",
        "\n",
        "        if augment_minority and len(category_images) < 300:\n",
        "            print(f\"üîÅ Augmenting class '{category}' with {len(category_images)} images\")\n",
        "            category_images = category_images.reshape((-1, img_size[0], img_size[1], 3))\n",
        "            extra = 300 - len(category_images)\n",
        "            aug_iter = datagen_aug.flow(category_images, batch_size=1)\n",
        "            for _ in range(extra):\n",
        "                aug_img = next(aug_iter)[0].astype(np.uint8)\n",
        "                images.append(aug_img)\n",
        "                labels.append(label)\n",
        "\n",
        "        for img in category_images:\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = to_categorical(labels, num_classes=len(categories))\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "YA0RoTvkXGmI"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load Data ---\n",
        "categories = ['Normal', 'Ischemic', 'Haemorrhagic']\n",
        "data_path = '/content/stroke_dataset/Stroke_classification'\n",
        "images, labels = load_data(data_path, categories)\n",
        "\n",
        "labels_numeric = np.argmax(labels, axis=1)\n",
        "print(\"Class distribution:\", Counter(labels_numeric))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ohj6QnzaKBzS",
        "outputId": "2a7eec84-cf1c-4072-87ef-0b604c91eb27"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÅ Augmenting class 'Ischemic' with 30 images\n",
            "üîÅ Augmenting class 'Haemorrhagic' with 186 images\n",
            "Class distribution: Counter({np.int64(0): 399, np.int64(1): 300, np.int64(2): 300})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: check class balance\n",
        "labels_numeric = np.argmax(labels, axis=1)\n",
        "print(\"Class distribution:\", Counter(labels_numeric))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw9AHKb8UGHN",
        "outputId": "844f68c4-881c-4a6e-c605-c056e0a0bd14"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution: Counter({np.int64(0): 399, np.int64(1): 300, np.int64(2): 300})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Split Data ---\n",
        "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, stratify=labels, random_state=42)"
      ],
      "metadata": {
        "id": "Zog_y0ybUNT_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Data Augmentation ---\n",
        "datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.6, 1.4],\n",
        "    shear_range=0.2,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "train_generator = datagen.flow(x_train, y_train, batch_size=32)"
      ],
      "metadata": {
        "id": "1UzaFoc-KB4U"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Class Weights ---\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(labels_numeric), y=labels_numeric)\n",
        "class_weights = {i: w for i, w in enumerate(class_weights)}\n",
        "print(\"Class Weights:\", class_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHpH5mvMX12O",
        "outputId": "8de87627-b553-40a2-fadd-933f1ab0c941"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: {0: np.float64(0.8345864661654135), 1: np.float64(1.11), 2: np.float64(1.11)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Model ---\n",
        "def build_model(input_shape=(224, 224, 3), num_classes=3):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    base_model = EfficientNetB0(input_tensor=inputs, include_top=False, weights='imagenet')\n",
        "    base_model.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7cSQPIzKB51",
        "outputId": "39ed53df-36d8-4c57-d6cb-5799f4cf5b68"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Callbacks ---\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)"
      ],
      "metadata": {
        "id": "wwDIYkdTr8SG"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Train Model (initial) ---\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=25,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[early_stop, reduce_lr, checkpoint],\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YxIt5ikKB8U",
        "outputId": "f214c92a-7c33-4a78-885e-f8b8b838118f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3525 - loss: 2.1084"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 4s/step - accuracy: 0.3538 - loss: 2.1012 - val_accuracy: 0.5600 - val_loss: 1.0111 - learning_rate: 1.0000e-04\n",
            "Epoch 2/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3s/step - accuracy: 0.4089 - loss: 1.7908 - val_accuracy: 0.5050 - val_loss: 0.9216 - learning_rate: 1.0000e-04\n",
            "Epoch 3/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.5476 - loss: 1.2642 - val_accuracy: 0.5300 - val_loss: 0.8629 - learning_rate: 1.0000e-04\n",
            "Epoch 4/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5672 - loss: 1.1129"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.5683 - loss: 1.1115 - val_accuracy: 0.5700 - val_loss: 0.8103 - learning_rate: 1.0000e-04\n",
            "Epoch 5/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5905 - loss: 1.0090"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 3s/step - accuracy: 0.5919 - loss: 1.0066 - val_accuracy: 0.6050 - val_loss: 0.7455 - learning_rate: 1.0000e-04\n",
            "Epoch 6/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6793 - loss: 0.8173"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.6781 - loss: 0.8217 - val_accuracy: 0.6750 - val_loss: 0.6937 - learning_rate: 1.0000e-04\n",
            "Epoch 7/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6358 - loss: 0.9815"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.6370 - loss: 0.9791 - val_accuracy: 0.6900 - val_loss: 0.6472 - learning_rate: 1.0000e-04\n",
            "Epoch 8/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6850 - loss: 0.8969"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.6844 - loss: 0.8971 - val_accuracy: 0.7500 - val_loss: 0.5617 - learning_rate: 1.0000e-04\n",
            "Epoch 9/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6992 - loss: 0.7649"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 3s/step - accuracy: 0.6992 - loss: 0.7641 - val_accuracy: 0.7900 - val_loss: 0.5038 - learning_rate: 1.0000e-04\n",
            "Epoch 10/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7259 - loss: 0.8012"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3s/step - accuracy: 0.7258 - loss: 0.7999 - val_accuracy: 0.8050 - val_loss: 0.4638 - learning_rate: 1.0000e-04\n",
            "Epoch 11/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7727 - loss: 0.6195"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.7718 - loss: 0.6215 - val_accuracy: 0.8650 - val_loss: 0.4007 - learning_rate: 1.0000e-04\n",
            "Epoch 12/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.7502 - loss: 0.6885 - val_accuracy: 0.8500 - val_loss: 0.3911 - learning_rate: 1.0000e-04\n",
            "Epoch 13/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7483 - loss: 0.6545"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3s/step - accuracy: 0.7480 - loss: 0.6558 - val_accuracy: 0.8750 - val_loss: 0.3615 - learning_rate: 1.0000e-04\n",
            "Epoch 14/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.7684 - loss: 0.5855 - val_accuracy: 0.8700 - val_loss: 0.3490 - learning_rate: 1.0000e-04\n",
            "Epoch 15/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - accuracy: 0.7726 - loss: 0.5660 - val_accuracy: 0.8700 - val_loss: 0.3518 - learning_rate: 1.0000e-04\n",
            "Epoch 16/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7773 - loss: 0.6086"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 4s/step - accuracy: 0.7774 - loss: 0.6088 - val_accuracy: 0.8850 - val_loss: 0.3062 - learning_rate: 1.0000e-04\n",
            "Epoch 17/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7900 - loss: 0.5455"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.7897 - loss: 0.5460 - val_accuracy: 0.9050 - val_loss: 0.2842 - learning_rate: 1.0000e-04\n",
            "Epoch 18/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7818 - loss: 0.6170"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.7817 - loss: 0.6161 - val_accuracy: 0.9150 - val_loss: 0.2751 - learning_rate: 1.0000e-04\n",
            "Epoch 19/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 4s/step - accuracy: 0.8322 - loss: 0.4484 - val_accuracy: 0.9150 - val_loss: 0.2629 - learning_rate: 1.0000e-04\n",
            "Epoch 20/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.7879 - loss: 0.5264 - val_accuracy: 0.9050 - val_loss: 0.2747 - learning_rate: 1.0000e-04\n",
            "Epoch 21/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.7850 - loss: 0.5725 - val_accuracy: 0.8900 - val_loss: 0.2869 - learning_rate: 1.0000e-04\n",
            "Epoch 22/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 3s/step - accuracy: 0.7787 - loss: 0.5511 - val_accuracy: 0.8750 - val_loss: 0.2910 - learning_rate: 1.0000e-04\n",
            "Epoch 23/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3s/step - accuracy: 0.8176 - loss: 0.4630 - val_accuracy: 0.8850 - val_loss: 0.2809 - learning_rate: 2.0000e-05\n",
            "Epoch 24/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.8435 - loss: 0.3958 - val_accuracy: 0.8850 - val_loss: 0.2728 - learning_rate: 2.0000e-05\n",
            "Epoch 25/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.7969 - loss: 0.4972 - val_accuracy: 0.8850 - val_loss: 0.2705 - learning_rate: 2.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Fine-tune EfficientNet ---\n",
        "model.load_weights('best_model.h5')\n",
        "model.get_layer(index=1).trainable = True  # Unfreeze EfficientNet\n",
        "for layer in model.layers[-40:]:  # fine-tune last 40 layers\n",
        "    if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "        layer.trainable = True\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "mf43w6OtfbT9"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Train Model (fine-tuning) ---\n",
        "fine_tune_history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=50,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br134jyGKB-D",
        "outputId": "5d4825b8-4fb8-431c-9687-f2f99071ddad"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 4s/step - accuracy: 0.7661 - loss: 0.6461 - val_accuracy: 0.9050 - val_loss: 0.2655 - learning_rate: 1.0000e-05\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 4s/step - accuracy: 0.7816 - loss: 0.5993 - val_accuracy: 0.8950 - val_loss: 0.2648 - learning_rate: 1.0000e-05\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 4s/step - accuracy: 0.8061 - loss: 0.5148 - val_accuracy: 0.9100 - val_loss: 0.2501 - learning_rate: 1.0000e-05\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 4s/step - accuracy: 0.7855 - loss: 0.5484 - val_accuracy: 0.9150 - val_loss: 0.2388 - learning_rate: 1.0000e-05\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3s/step - accuracy: 0.8091 - loss: 0.4835 - val_accuracy: 0.9200 - val_loss: 0.2313 - learning_rate: 1.0000e-05\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 4s/step - accuracy: 0.7987 - loss: 0.5301 - val_accuracy: 0.9000 - val_loss: 0.2415 - learning_rate: 1.0000e-05\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 4s/step - accuracy: 0.8075 - loss: 0.4974 - val_accuracy: 0.8950 - val_loss: 0.2415 - learning_rate: 1.0000e-05\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3s/step - accuracy: 0.8171 - loss: 0.5094 - val_accuracy: 0.9050 - val_loss: 0.2336 - learning_rate: 1.0000e-05\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 4s/step - accuracy: 0.8302 - loss: 0.4583 - val_accuracy: 0.9050 - val_loss: 0.2318 - learning_rate: 2.0000e-06\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 4s/step - accuracy: 0.8301 - loss: 0.4988 - val_accuracy: 0.9100 - val_loss: 0.2262 - learning_rate: 2.0000e-06\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 4s/step - accuracy: 0.8035 - loss: 0.4742 - val_accuracy: 0.9100 - val_loss: 0.2261 - learning_rate: 2.0000e-06\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 4s/step - accuracy: 0.8187 - loss: 0.5012 - val_accuracy: 0.9150 - val_loss: 0.2213 - learning_rate: 2.0000e-06\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 4s/step - accuracy: 0.8375 - loss: 0.4265 - val_accuracy: 0.9200 - val_loss: 0.2195 - learning_rate: 2.0000e-06\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 4s/step - accuracy: 0.7805 - loss: 0.5024 - val_accuracy: 0.9200 - val_loss: 0.2177 - learning_rate: 2.0000e-06\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 4s/step - accuracy: 0.8236 - loss: 0.4931 - val_accuracy: 0.9200 - val_loss: 0.2170 - learning_rate: 2.0000e-06\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.8002 - loss: 0.4871 - val_accuracy: 0.9150 - val_loss: 0.2200 - learning_rate: 2.0000e-06\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 4s/step - accuracy: 0.8287 - loss: 0.4597 - val_accuracy: 0.9150 - val_loss: 0.2198 - learning_rate: 2.0000e-06\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 4s/step - accuracy: 0.8368 - loss: 0.4240 - val_accuracy: 0.9150 - val_loss: 0.2181 - learning_rate: 2.0000e-06\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 4s/step - accuracy: 0.8467 - loss: 0.4053 - val_accuracy: 0.9150 - val_loss: 0.2170 - learning_rate: 1.0000e-06\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 4s/step - accuracy: 0.8067 - loss: 0.5054 - val_accuracy: 0.9250 - val_loss: 0.2141 - learning_rate: 1.0000e-06\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 4s/step - accuracy: 0.8370 - loss: 0.4613 - val_accuracy: 0.9150 - val_loss: 0.2139 - learning_rate: 1.0000e-06\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 4s/step - accuracy: 0.8231 - loss: 0.4851 - val_accuracy: 0.9150 - val_loss: 0.2132 - learning_rate: 1.0000e-06\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.8092 - loss: 0.4805 - val_accuracy: 0.9200 - val_loss: 0.2131 - learning_rate: 1.0000e-06\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 4s/step - accuracy: 0.8254 - loss: 0.4084 - val_accuracy: 0.9250 - val_loss: 0.2111 - learning_rate: 1.0000e-06\n",
            "Epoch 25/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 4s/step - accuracy: 0.8360 - loss: 0.3958 - val_accuracy: 0.9300 - val_loss: 0.2079 - learning_rate: 1.0000e-06\n",
            "Epoch 26/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 4s/step - accuracy: 0.8205 - loss: 0.4208 - val_accuracy: 0.9250 - val_loss: 0.2086 - learning_rate: 1.0000e-06\n",
            "Epoch 27/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 4s/step - accuracy: 0.8599 - loss: 0.3955 - val_accuracy: 0.9200 - val_loss: 0.2112 - learning_rate: 1.0000e-06\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 4s/step - accuracy: 0.8548 - loss: 0.3994 - val_accuracy: 0.9200 - val_loss: 0.2101 - learning_rate: 1.0000e-06\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.8202 - loss: 0.4379 - val_accuracy: 0.9250 - val_loss: 0.2093 - learning_rate: 1.0000e-06\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 4s/step - accuracy: 0.7895 - loss: 0.4728 - val_accuracy: 0.9250 - val_loss: 0.2097 - learning_rate: 1.0000e-06\n",
            "Epoch 31/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 4s/step - accuracy: 0.8175 - loss: 0.4773 - val_accuracy: 0.9300 - val_loss: 0.2076 - learning_rate: 1.0000e-06\n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 4s/step - accuracy: 0.8278 - loss: 0.4476 - val_accuracy: 0.9300 - val_loss: 0.2081 - learning_rate: 1.0000e-06\n",
            "Epoch 33/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.8273 - loss: 0.4424 - val_accuracy: 0.9300 - val_loss: 0.2077 - learning_rate: 1.0000e-06\n",
            "Epoch 34/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 4s/step - accuracy: 0.8202 - loss: 0.4557 - val_accuracy: 0.9300 - val_loss: 0.2078 - learning_rate: 1.0000e-06\n",
            "Epoch 35/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 4s/step - accuracy: 0.8292 - loss: 0.4099 - val_accuracy: 0.9300 - val_loss: 0.2074 - learning_rate: 1.0000e-06\n",
            "Epoch 36/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3s/step - accuracy: 0.8289 - loss: 0.4402 - val_accuracy: 0.9300 - val_loss: 0.2050 - learning_rate: 1.0000e-06\n",
            "Epoch 37/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.7937 - loss: 0.4672 - val_accuracy: 0.9300 - val_loss: 0.2046 - learning_rate: 1.0000e-06\n",
            "Epoch 38/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - accuracy: 0.8217 - loss: 0.4619 - val_accuracy: 0.9250 - val_loss: 0.2073 - learning_rate: 1.0000e-06\n",
            "Epoch 39/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.8458 - loss: 0.4064 - val_accuracy: 0.9250 - val_loss: 0.2085 - learning_rate: 1.0000e-06\n",
            "Epoch 40/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 4s/step - accuracy: 0.8029 - loss: 0.5684 - val_accuracy: 0.9250 - val_loss: 0.2080 - learning_rate: 1.0000e-06\n",
            "Epoch 41/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 4s/step - accuracy: 0.8207 - loss: 0.5035 - val_accuracy: 0.9250 - val_loss: 0.2091 - learning_rate: 1.0000e-06\n",
            "Epoch 42/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 4s/step - accuracy: 0.8459 - loss: 0.4098 - val_accuracy: 0.9150 - val_loss: 0.2085 - learning_rate: 1.0000e-06\n",
            "Epoch 43/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 4s/step - accuracy: 0.8508 - loss: 0.4417 - val_accuracy: 0.9150 - val_loss: 0.2092 - learning_rate: 1.0000e-06\n",
            "Epoch 44/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 4s/step - accuracy: 0.8117 - loss: 0.4848 - val_accuracy: 0.9150 - val_loss: 0.2099 - learning_rate: 1.0000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Evaluate Model ---\n",
        "model.load_weights('best_model.h5')\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(classification_report(y_true, y_pred_classes, target_names=categories))\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "c59uNusLOi-n",
        "outputId": "bdc5e6be-bfc6-4774-bec8-b36d123d9768"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.85      0.97      0.91        80\n",
            "    Ischemic       0.98      0.98      0.98        60\n",
            "Haemorrhagic       0.96      0.77      0.85        60\n",
            "\n",
            "    accuracy                           0.92       200\n",
            "   macro avg       0.93      0.91      0.91       200\n",
            "weighted avg       0.92      0.92      0.91       200\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2wU4psaBXwKw5LS06iBIcETQAri_3Y8RFY6wiv4iMgGC5Rut3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgxnNtdbr-FZ",
        "outputId": "bf667df8-d9cf-4ff8-ae51-f0355de453d4"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok\n",
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z53Xz_L6oz4j",
        "outputId": "a4153650-b39d-48a5-c463-b2ea18fcd2d8"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.36.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.5)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.28.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.10.0 (from gradio)\n",
            "  Downloading gradio_client-1.10.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.28.0-py3-none-any.whl (54.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.28.0 gradio-client-1.10.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.7 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fpdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFThrP143kWv",
        "outputId": "0bd3089e-a9ff-4a21-d9a1-e4b13242db76"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=2d9b03e053e14ccc712a85e22bffb98d70e6e5edac9ad4021310c2d5a33deb0a\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/66/bbda9866da446a72e206d6484cd97381cbc7859a7068541c36\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import datetime\n",
        "import cv2\n",
        "import io\n",
        "from fpdf import FPDF\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "\n",
        "# Load your trained model and categories\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model(\"best_model.h5\")  # replace with your actual model file path\n",
        "categories = [\"No Stroke\", \"Ischemic\", \"Hemorrhagic\"]  # adjust based on your trained labels\n",
        "\n",
        "# Function to create PDF from text\n",
        "def generate_pdf(report_text):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_auto_page_break(auto=True, margin=15)\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "\n",
        "    for line in report_text.split(\"\\n\"):\n",
        "        pdf.multi_cell(0, 10, line)\n",
        "\n",
        "    pdf_output = io.BytesIO()\n",
        "    pdf_bytes = pdf.output(dest='S').encode('latin-1')\n",
        "    pdf_output.write(pdf_bytes)\n",
        "    pdf_output.seek(0)\n",
        "    return pdf_output\n",
        "\n",
        "# Actual prediction function\n",
        "def predict(image, name, gender, scan_type):\n",
        "    if scan_type != \"MRI\":\n",
        "        return \"Coming Soon\", \"N/A\", \"N/A\", \"CT prediction not supported yet.\", None\n",
        "\n",
        "    # Convert PIL to OpenCV format\n",
        "    img = np.array(image)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = preprocess_input(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    prediction = model.predict(img)\n",
        "    pred_class = np.argmax(prediction)\n",
        "    confidence = np.max(prediction)\n",
        "\n",
        "    result = \"Stroke Detected\" if pred_class != 0 else \"No Stroke\"\n",
        "    stroke_type = categories[pred_class] if pred_class != 0 else \"None\"\n",
        "\n",
        "    # Generate report\n",
        "    now = datetime.datetime.now()\n",
        "    report = f\"\"\"\n",
        "    Stroke Sense ‚Äì AI Stroke Detection Report\n",
        "    Date: {now.strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "    Patient Name: {name or 'N/A'}\n",
        "    Gender: {gender}\n",
        "    Scan Type: {scan_type}\n",
        "\n",
        "    Diagnosis: {result}\n",
        "    Stroke Type: {stroke_type}\n",
        "    Confidence: {confidence * 100:.2f}%\n",
        "\n",
        "    Summary:\n",
        "    The uploaded {scan_type} scan shows radiological features indicating a {stroke_type.lower()} stroke.\n",
        "    Further medical consultation is advised.\n",
        "\n",
        "    This report was generated automatically by Stroke Sense.\n",
        "    \"\"\"\n",
        "\n",
        "    pdf_file = generate_pdf(report)\n",
        "    return result, stroke_type, f\"{confidence*100:.2f}%\", report, (\"stroke_report.pdf\", pdf_file)\n",
        "\n",
        "# Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\"),\n",
        "        gr.Textbox(label=\"Patient Name\"),\n",
        "        gr.Radio(choices=[\"Male\", \"Female\", \"Other\"], label=\"Gender\"),\n",
        "        gr.Radio(choices=[\"MRI\", \"CT (Coming Soon)\"], label=\"Scan Type\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Diagnosis Result\"),\n",
        "        gr.Textbox(label=\"Stroke Type\"),\n",
        "        gr.Textbox(label=\"Model Confidence\"),\n",
        "        gr.Textbox(label=\"Generated Report\", lines=10),\n",
        "        gr.File(label=\"Download PDF Report\")\n",
        "    ],\n",
        "    title=\"Stroke Sense ‚Äì AI Stroke Detection\",\n",
        "    description=\"Upload a brain scan and enter patient info to generate a medical diagnosis report using AI.\"\n",
        ")\n",
        "\n",
        "interface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "wdkh_GPy7wX4",
        "outputId": "b3488b30-c1b3-4256-bc15-296d45a1694c"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://08b3dcb195382796c2.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://08b3dcb195382796c2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import datetime\n",
        "import cv2\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "\n",
        "# Load your trained model and categories\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model(\"best_model.h5\")  # replace with your actual model file path\n",
        "categories = [\"No Stroke\", \"Ischemic\", \"Hemorrhagic\"]  # adjust based on your trained labels\n",
        "\n",
        "# Actual prediction function\n",
        "def predict(image, name, gender, scan_type):\n",
        "    if scan_type != \"MRI\":\n",
        "        return \"Coming Soon\", \"N/A\", \"N/A\", \"CT prediction not supported yet.\"\n",
        "\n",
        "    # Convert PIL to OpenCV format\n",
        "    img = np.array(image)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = preprocess_input(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    prediction = model.predict(img)\n",
        "    pred_class = np.argmax(prediction)\n",
        "    confidence = np.max(prediction)\n",
        "\n",
        "    result = \"Stroke Detected\" if pred_class != 0 else \"No Stroke\"\n",
        "    stroke_type = categories[pred_class] if pred_class != 0 else \"None\"\n",
        "\n",
        "    # Generate report\n",
        "    now = datetime.datetime.now()\n",
        "    report = f\"\"\"\n",
        "    Stroke Sense ‚Äì AI Stroke Detection Report\n",
        "    Date: {now.strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "    Patient Name: {name or 'N/A'}\n",
        "    Gender: {gender}\n",
        "    Scan Type: {scan_type}\n",
        "\n",
        "    Diagnosis: {result}\n",
        "    Stroke Type: {stroke_type}\n",
        "    Confidence: {confidence * 100:.2f}%\n",
        "\n",
        "    Summary:\n",
        "    The uploaded {scan_type} scan shows radiological features indicating a {stroke_type.lower()} stroke.\n",
        "    Further medical consultation is advised.\n",
        "\n",
        "    This report was generated automatically by Stroke Sense.\n",
        "    \"\"\"\n",
        "\n",
        "    return result, stroke_type, f\"{confidence*100:.2f}%\", report\n",
        "\n",
        "# Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\"),\n",
        "        gr.Textbox(label=\"Patient Name\"),\n",
        "        gr.Radio(choices=[\"Male\", \"Female\", \"Other\"], label=\"Gender\"),\n",
        "        gr.Radio(choices=[\"MRI\", \"CT (Coming Soon)\"], label=\"Scan Type\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Diagnosis Result\"),\n",
        "        gr.Textbox(label=\"Stroke Type\"),\n",
        "        gr.Textbox(label=\"Model Confidence\"),\n",
        "        gr.Textbox(label=\"Generated Report\", lines=10)\n",
        "    ],\n",
        "    title=\"Stroke Sense ‚Äì AI Stroke Detection\",\n",
        "    description=\"Upload a brain scan and enter patient info to generate a medical diagnosis report using AI.\"\n",
        ")\n",
        "\n",
        "interface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "YoIQB0V1yCyA",
        "outputId": "0f263403-f293-4286-ae3d-1424f56a18c4"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://adb15a5dcc0c1061a7.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://adb15a5dcc0c1061a7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import datetime\n",
        "\n",
        "# Dummy model for demonstration purposes (replace with actual model prediction logic)\n",
        "def predict(image, name, gender, scan_type):\n",
        "    # Simulate prediction output\n",
        "    result = \"Stroke Detected\"\n",
        "    stroke_type = \"Ischemic\"\n",
        "    confidence = 0.89\n",
        "\n",
        "    # Generate report\n",
        "    now = datetime.datetime.now()\n",
        "    report = f\"\"\"\n",
        "    Stroke Sense ‚Äì AI Stroke Detection Report\n",
        "    Date: {now.strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "    Patient Name: {name or 'N/A'}\n",
        "    Gender: {gender}\n",
        "    Scan Type: {scan_type}\n",
        "\n",
        "    Diagnosis: {result}\n",
        "    Stroke Type: {stroke_type}\n",
        "    Confidence: {confidence * 100:.2f}%\n",
        "\n",
        "    Summary:\n",
        "    The uploaded {scan_type} scan shows radiological features indicating a {stroke_type.lower()} stroke.\n",
        "    Further medical consultation is advised.\n",
        "\n",
        "    This report was generated automatically by Stroke Sense.\n",
        "    \"\"\"\n",
        "\n",
        "    return result, stroke_type, f\"{confidence*100:.2f}%\", report\n",
        "\n",
        "# Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\"),\n",
        "        gr.Textbox(label=\"Patient Name\"),\n",
        "        gr.Radio(choices=[\"Male\", \"Female\", \"Other\"], label=\"Gender\"),\n",
        "        gr.Radio(choices=[\"MRI\", \"CT (Coming Soon)\"], label=\"Scan Type\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Diagnosis Result\"),\n",
        "        gr.Textbox(label=\"Stroke Type\"),\n",
        "        gr.Textbox(label=\"Model Confidence\"),\n",
        "        gr.Textbox(label=\"Generated Report\", lines=10)\n",
        "    ],\n",
        "    title=\"Stroke Sense ‚Äì AI Stroke Detection\",\n",
        "    description=\"Upload a brain scan and enter patient info to generate a medical diagnosis report using AI.\"\n",
        ")\n",
        "\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "Q_PxS9hro4bA",
        "outputId": "df15930b-a256-444d-b53e-86b0da46c35b"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5fed6bc07614b004f3.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5fed6bc07614b004f3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import datetime\n",
        "\n",
        "# Dummy prediction function (replace with your actual model call)\n",
        "def predict_stroke(image_array):\n",
        "    # Example dummy result\n",
        "    return {\n",
        "        \"result\": \"Stroke Detected\",\n",
        "        \"type\": \"Ischemic\",\n",
        "        \"confidence\": 0.897\n",
        "    }\n",
        "\n",
        "# Title\n",
        "st.title(\"Stroke Sense ‚Äì AI Stroke Detection\")\n",
        "\n",
        "# Sidebar user info\n",
        "st.sidebar.header(\"Patient Information\")\n",
        "patient_name = st.sidebar.text_input(\"Name\")\n",
        "patient_gender = st.sidebar.selectbox(\"Gender\", [\"Male\", \"Female\", \"Other\"])\n",
        "scan_type = st.sidebar.selectbox(\"Scan Type\", [\"MRI\", \"CT (Coming Soon)\"])\n",
        "uploaded_image = st.file_uploader(\"Upload MRI Image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "# Prediction and report section\n",
        "if uploaded_image and scan_type == \"MRI\":\n",
        "    image = Image.open(uploaded_image).convert(\"RGB\")\n",
        "    st.image(image, caption=\"Uploaded MRI Image\", use_column_width=True)\n",
        "\n",
        "    # Convert image to array (resize & preprocess as needed)\n",
        "    image_array = np.array(image.resize((224, 224))) / 255.0\n",
        "\n",
        "    # Predict\n",
        "    result = predict_stroke(image_array)\n",
        "\n",
        "    st.subheader(\"Prediction Result\")\n",
        "    st.write(f\"**Result:** {result['result']}\")\n",
        "    st.write(f\"**Stroke Type:** {result['type']}\")\n",
        "    st.write(f\"**Confidence:** {result['confidence'] * 100:.2f}%\")\n",
        "\n",
        "    # Generate report\n",
        "    st.subheader(\"Generated Medical Report\")\n",
        "    now = datetime.datetime.now()\n",
        "    report_text = f\"\"\"\n",
        "    Stroke Sense ‚Äì AI Stroke Detection System Report\n",
        "    Date: {now.strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "    Patient Name: {patient_name or 'N/A'}\n",
        "    Gender: {patient_gender}\n",
        "    Scan Type: {scan_type}\n",
        "\n",
        "    Diagnosis: {result['result']}\n",
        "    Stroke Type: {result['type']}\n",
        "    Confidence: {result['confidence'] * 100:.2f}%\n",
        "\n",
        "    Summary:\n",
        "    The uploaded {scan_type} scan indicates radiological signs consistent with a {result['type'].lower()} stroke.\n",
        "    Further clinical assessment is advised.\n",
        "\n",
        "    This report was generated automatically by Stroke Sense ‚Äì AI-Powered Detection System.\n",
        "    \"\"\"\n",
        "    st.text_area(\"Medical Report\", report_text, height=300)\n",
        "\n",
        "    # Downloadable report (optional future)\n",
        "    # st.download_button(\"Download Report\", report_text, file_name=\"stroke_report.txt\")\n",
        "\n",
        "elif uploaded_image and scan_type == \"CT (Coming Soon)\":\n",
        "    st.warning(\"CT scan analysis is currently under development. Please use an MRI image.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhnmKzh0onb5",
        "outputId": "f8f9f7d2-c220-4b18-bffb-a62f49b6227b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-01 07:12:05.865 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.868 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.872 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.874 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.877 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.883 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.886 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.888 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.891 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.893 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.897 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.898 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.900 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.902 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.904 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.907 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.909 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.912 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.914 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.919 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.929 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.930 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.931 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.933 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.934 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.934 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-01 07:12:05.936 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "conf.get_default().auth_token = \"2wU4psaBXwKw5LS06iBIcETQAri_3Y8RFY6wiv4iMgGC5Rut3\"\n",
        "# Specify the tunnel configuration with 'addr' for HTTP tunnels\n",
        "public_url = ngrok.connect(addr=8501)\n",
        "print(f\"‚úÖ Open your Streamlit app here: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57re-aFbrfH7",
        "outputId": "d3fd4528-f2a0-4ef8-cbde-9e22082d93b5"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Open your Streamlit app here: NgrokTunnel: \"https://92ce-34-83-197-98.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import conf, ngrok\n",
        "\n",
        "# ÿ±ÿ®ÿ∑ ÿßŸÑÿ™ŸàŸÉŸÜ\n",
        "conf.get_default().auth_token = \"2wU4psaBXwKw5LS06iBIcETQAri_3Y8RFY6wiv4iMgGC5Rut3\"\n",
        "\n",
        "# ŸÅÿ™ÿ≠ ŸÜŸÅŸÇ ÿπŸÑŸâ ÿ®Ÿàÿ±ÿ™ 8501 (ÿ≠ŸÇ Streamlit)\n",
        "public_url = ngrok.connect(port=8501)\n",
        "print(f\"‚úÖ Open your Streamlit app here: {public_url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "1Iq3RAvwqz0X",
        "outputId": "c9d900f8-b622-48cc-8a94-00e463c95066"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-05-01T07:07:08+0000 lvl=warn msg=\"invalid tunnel configuration\" pg=/api/tunnels id=851806da4fdfd54f err=\"yaml: unmarshal errors:\\n  line 1: field port not found in type config.HTTPv2Tunnel\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PyngrokNgrokHTTPError",
          "evalue": "ngrok client exception, API returned 400: {\"error_code\":102,\"status_code\":400,\"msg\":\"invalid tunnel configuration\",\"details\":{\"err\":\"yaml: unmarshal errors:\\n  line 1: field port not found in type config.HTTPv2Tunnel\"}}\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout, auth)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0mresponse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    635\u001b[0m                 'http', request, response, code, msg, hdrs)\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 400: Bad Request",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mPyngrokNgrokHTTPError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-50c0c9b3a293>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# ŸÅÿ™ÿ≠ ŸÜŸÅŸÇ ÿπŸÑŸâ ÿ®Ÿàÿ±ÿ™ 8501 (ÿ≠ŸÇ Streamlit)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8501\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"‚úÖ Open your Streamlit app here: {public_url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Creating tunnel with options: {options}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     tunnel = NgrokTunnel(api_request(f\"{api_url}/api/tunnels\", method=\"POST\", data=options,\n\u001b[0m\u001b[1;32m    355\u001b[0m                                      timeout=pyngrok_config.request_timeout),\n\u001b[1;32m    356\u001b[0m                          pyngrok_config, api_url)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout, auth)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Response {status_code}: {response_data.strip()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         raise PyngrokNgrokHTTPError(f\"ngrok client exception, API returned {status_code}: {response_data}\",\n\u001b[0m\u001b[1;32m    578\u001b[0m                                     \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m                                     status_code, e.reason, e.headers, response_data)\n",
            "\u001b[0;31mPyngrokNgrokHTTPError\u001b[0m: ngrok client exception, API returned 400: {\"error_code\":102,\"status_code\":400,\"msg\":\"invalid tunnel configuration\",\"details\":{\"err\":\"yaml: unmarshal errors:\\n  line 1: field port not found in type config.HTTPv2Tunnel\"}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# ÿ•ŸÜÿ¥ÿßÿ° ŸÜŸÅŸÇ HTTP ŸÑŸÖŸÜŸÅÿ∞ Streamlit\n",
        "public_url = ngrok.connect(port=8501)\n",
        "print(f\"Open the app here üëâ {public_url}\")\n",
        "\n",
        "# ÿ™ÿ¥ÿ∫ŸäŸÑ streamlit ÿØÿßÿÆŸÑ ÿßŸÑŸÉŸàŸÑÿßÿ®\n",
        "!streamlit run app.py &>/dev/null &\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "WUCHYep8pH4J",
        "outputId": "cc4fba24-7bbd-47aa-b6a6-ac07131f5e75"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pyngrok.process.ngrok:t=2025-05-01T06:59:50+0000 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-05-01T06:59:50+0000 lvl=eror msg=\"session closing\" obj=tunnels.session err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-05-01T06:59:50+0000 lvl=eror msg=\"terminating with error\" obj=app err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
            "CRITICAL:pyngrok.process.ngrok:t=2025-05-01T06:59:50+0000 lvl=crit msg=\"command failed\" err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-05-01T06:59:50+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context canceled\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PyngrokNgrokError",
          "evalue": "The ngrok process errored on start: authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-24c9e669e71c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ÿ•ŸÜÿ¥ÿßÿ° ŸÜŸÅŸÇ HTTP ŸÑŸÖŸÜŸÅÿ∞ Streamlit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8501\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Open the app here üëâ {public_url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Opening tunnel named: {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0mapi_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ngrok_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Creating tunnel with options: {options}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mget_ngrok_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0minstall_ngrok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36mget_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_current_processes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngrok_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_start_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36m_start_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartup_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             raise PyngrokNgrokError(f\"The ngrok process errored on start: {ngrok_process.startup_error}.\",\n\u001b[0m\u001b[1;32m    429\u001b[0m                                     \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                     ngrok_process.startup_error)\n",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m: The ngrok process errored on start: authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Predict on New Image Haemorrhagic ---\n",
        "def predict_image(image_path, model, img_size=(224, 224), categories=None):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, img_size)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = preprocess_input(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    prediction = model.predict(img)\n",
        "    pred_class = np.argmax(prediction)\n",
        "    confidence = np.max(prediction)\n",
        "\n",
        "    label = categories[pred_class] if categories else pred_class\n",
        "    print(f\"‚úÖ Predicted: {label} ({confidence*100:.2f}%)\")\n",
        "\n",
        "    plt.imshow(cv2.imread(image_path)[..., ::-1])\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Prediction: {label} ({confidence*100:.2f}%)\")\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "predict_image('/content/Haemorrhagic_examole.png', model, categories=categories)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "YGCyr5oqKCFq",
        "outputId": "4a5ed65d-b3ff-4fcd-f726-47679b100e8d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-cff4813d6436>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Example usage:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mpredict_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Haemorrhagic_examole.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-43-cff4813d6436>\u001b[0m in \u001b[0;36mpredict_image\u001b[0;34m(image_path, model, img_size, categories)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Predict on New Image Ischemic---\n",
        "def predict_image(image_path, model, img_size=(224, 224), categories=None):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, img_size)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = preprocess_input(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    prediction = model.predict(img)\n",
        "    pred_class = np.argmax(prediction)\n",
        "    confidence = np.max(prediction)\n",
        "\n",
        "    label = categories[pred_class] if categories else pred_class\n",
        "    print(f\"‚úÖ Predicted: {label} ({confidence*100:.2f}%)\")\n",
        "\n",
        "    plt.imshow(cv2.imread(image_path)[..., ::-1])\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Prediction: {label} ({confidence*100:.2f}%)\")\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "predict_image('/content/Ischemic_example.png', model, categories=categories)\n"
      ],
      "metadata": {
        "id": "QLHjdMR0nAbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Predict on New Image ---\n",
        "def predict_image(image_path, model, img_size=(224, 224), categories=None):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, img_size)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = preprocess_input(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    prediction = model.predict(img)\n",
        "    pred_class = np.argmax(prediction)\n",
        "    confidence = np.max(prediction)\n",
        "\n",
        "    label = categories[pred_class] if categories else pred_class\n",
        "    print(f\"‚úÖ Predicted: {label} ({confidence*100:.2f}%)\")\n",
        "\n",
        "    plt.imshow(cv2.imread(image_path)[..., ::-1])\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Prediction: {label} ({confidence*100:.2f}%)\")\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "predict_image('/content/Bushan Yadav DWI-13.jpg_Normal_207.png', model, categories=categories)\n"
      ],
      "metadata": {
        "id": "75AwNQTLnA27"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}